"""
Found 28709 images belonging to 7 classes.
Found 7178 images belonging to 7 classes.
Categories and number of images in each category:
angry: 3995 images
disgust: 436 images
fear: 4097 images
happy: 7215 images
neutral: 4965 images
sad: 4830 images
surprise: 3171 images
Categories and number of images in each category:
angry: 958 images
disgust: 111 images
fear: 1024 images
happy: 1774 images
neutral: 1233 images
sad: 1247 images
surprise: 831 images
KNN Test Accuracy: 0.2938
KNN Classification Report:
              precision    recall  f1-score   support

           0       0.20      0.43      0.27       958
           1       0.17      0.33      0.23       111
           2       0.22      0.33      0.26      1024
           3       0.42      0.34      0.37      1774
           4       0.37      0.20      0.26      1233
           5       0.28      0.16      0.20      1247
           6       0.56      0.33      0.42       831

    accuracy                           0.29      7178
   macro avg       0.32      0.30      0.29      7178
weighted avg       0.34      0.29      0.30      7178

SVM Test Accuracy: 0.3373
SVM Classification Report:
              precision    recall  f1-score   support

           0       0.24      0.13      0.17       958
           1       0.00      0.00      0.00       111
           2       0.22      0.07      0.11      1024
           3       0.37      0.72      0.49      1774
           4       0.36      0.29      0.32      1233
           5       0.28      0.31      0.29      1247
           6       0.38      0.24      0.30       831

    accuracy                           0.34      7178
   macro avg       0.26      0.25      0.24      7178
weighted avg       0.31      0.34      0.30      7178

Random Forest Test Accuracy: 0.3721
Random Forest Classification Report:
              precision    recall  f1-score   support

           0       0.32      0.14      0.19       958
           1       1.00      0.23      0.38       111
           2       0.35      0.16      0.22      1024
           3       0.36      0.77      0.49      1774
           4       0.38      0.30      0.33      1233
           5       0.30      0.27      0.28      1247
           6       0.68      0.35      0.46       831

    accuracy                           0.37      7178
   macro avg       0.48      0.32      0.34      7178
weighted avg       0.39      0.37      0.34      7178

XGBoost Test Accuracy: 0.3568
XGBoost Classification Report:
              precision    recall  f1-score   support

           0       0.28      0.15      0.19       958
           1       0.92      0.10      0.18       111
           2       0.30      0.13      0.19      1024
           3       0.38      0.69      0.49      1774
           4       0.35      0.32      0.33      1233
           5       0.29      0.31      0.30      1247
           6       0.49      0.32      0.38       831

    accuracy                           0.36      7178
   macro avg       0.43      0.29      0.30      7178
weighted avg       0.36      0.36      0.33      7178
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from skimage.feature import local_binary_pattern
from skimage.color import rgb2gray
from sklearn.model_selection import StratifiedKFold, train_test_split
from sklearn.model_selection import GridSearchCV, cross_val_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report

# Paths for training and testing directories
train_dir = r'C:\Users\whisk\OneDrive\Desktop\ERDOS WORK\train_original'
testin_dir = r'C:\Users\whisk\OneDrive\Desktop\ERDOS WORK\test'

# Define an ImageDataGenerator without augmentation for loading
datagen = ImageDataGenerator(rescale=1./255)

# Load the images and labels from the directory

training = datagen.flow_from_directory(train_dir, target_size=(48, 48), batch_size=16, class_mode='categorical', shuffle=False)


testing = datagen.flow_from_directory(testin_dir, target_size=(48, 48), batch_size=16, class_mode='categorical', shuffle=False)

# Print category information
print("Categories and number of images in each category:")
for category, index in training.class_indices.items():
    num_images = sum(training.classes == index)
    print(f"{category}: {num_images} images")
print("Categories and number of images in each category:")
for category, index in testing.class_indices.items():
    num_images = sum(testing.classes == index)
    print(f"{category}: {num_images} images")


def apply_lbp(image, radius, n_points):
    """
    Apply Local Binary Pattern (LBP) to an image, using skimage.feature.

    Parameters:
    - image: The input image (grayscale).
    - radius: The radius of the circular LBP neighborhood.
    - n_points: Number of points to consider in the neighborhood.

    Returns:
    - LBP feature array.
    """
    lbp = local_binary_pattern(image, n_points, radius, method="uniform")
    return lbp

if __name__ == '__main__':
    radius = 3
    n_points = 24

    # Extract raw images and labels from the training generator
    X_images = []
    y_labels = []

    for i in range(len(training)):
        X_batch, y_batch = next(training)
        for img, label in zip(X_batch, y_batch):
            X_images.append(img)  # Keep the original image (not LBP features yet)
            y_labels.append(np.argmax(label))  # Convert one-hot encoding to class labels

    X_images = np.array(X_images)
    y_labels = np.array(y_labels)

    # Split raw training set into train_train and train_test
    X_train_train_raw, X_train_test_raw, y_train_train, y_train_test = train_test_split(
        X_images, y_labels, test_size=0.2, random_state=42
    )

    # Define a helper function to apply LBP
    def extract_lbp_features(images, radius, n_points):
        features = []
        for img in images:
            img_gray = rgb2gray(img)  # Convert to grayscale
            lbp_features = apply_lbp(img_gray, radius, n_points).flatten()  # Flatten LBP
            features.append(lbp_features)
        return np.array(features)

    # Apply LBP to train_train and train_test subsets
    X_train_train_features = extract_lbp_features(X_train_train_raw, radius, n_points)
    X_train_test_features = extract_lbp_features(X_train_test_raw, radius, n_points)

    # Feature scaling (using train_train only)
    scaler = StandardScaler()
    X_train_train_scaled = scaler.fit_transform(X_train_train_features)
    X_train_test_scaled = scaler.transform(X_train_test_features)

    # PCA for dimensionality reduction
    pca = PCA(n_components=50)
    X_train_train_reduced = pca.fit_transform(X_train_train_scaled)
    X_train_test_reduced = pca.transform(X_train_test_scaled)

    # Process testing set
    X_test_images = []
    y_test_labels = []

    for i in range(len(testing)):
        X_batch, y_batch = next(testing)
        for img, label in zip(X_batch, y_batch):
            X_test_images.append(img)
            y_test_labels.append(np.argmax(label))  # Extract class labels

    X_test_images = np.array(X_test_images)
    y_test_labels = np.array(y_test_labels)

    # Apply LBP to testing set
    X_test_features = extract_lbp_features(X_test_images, radius, n_points)
    X_test_scaled = scaler.transform(X_test_features)
    X_test_reduced = pca.transform(X_test_scaled)

    # Train and evaluate classifiers
    classifiers = {
        "KNN": KNeighborsClassifier(n_neighbors=3),
        "SVM": SVC(kernel='linear', C=1),
        "Random Forest": RandomForestClassifier(max_depth=50, max_features='sqrt', random_state=42),
        "XGBoost": XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1)
    }

    for name, clf in classifiers.items():
        clf.fit(X_train_train_reduced, y_train_train)
        y_pred = clf.predict(X_test_reduced)
        print(f"{name} Test Accuracy: {accuracy_score(y_test_labels, y_pred):.4f}")
        print(f"{name} Classification Report:\n{classification_report(y_test_labels, y_pred)}")


    
    
    
   
