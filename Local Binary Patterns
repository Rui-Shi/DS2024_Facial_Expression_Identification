import os
import cv2
import numpy as np
import pandas as pd
import random
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from skimage.feature import local_binary_pattern
from skimage.color import rgb2gray


train_dir = r'C:\Users\whisk\OneDrive\Desktop\ERDOS WORK\train'
balanced_dir = os.path.expanduser('~/Downloads/fer2013/train_balanced')
os.makedirs(balanced_dir, exist_ok=True)


datagen = ImageDataGenerator(rescale=1./255)
training = datagen.flow_from_directory(train_dir, target_size=(48, 48), batch_size=16, class_mode='categorical', shuffle=False)


train_images = []
train_labels = []
for _ in range(len(training)):
    X_batch, y_batch = next(training)
    train_images.extend(X_batch)
    train_labels.extend(np.argmax(y_batch, axis=1))  


num_images_to_keep = 5000
balanced_images = []
balanced_labels = []


happy_images = [img for img, label in zip(train_images, train_labels) if label == 3]  # Assuming '3' is happy
if len(happy_images) > num_images_to_keep:
    selected_happy_images = random.sample(happy_images, num_images_to_keep)
else:
    selected_happy_images = happy_images
balanced_images.extend(selected_happy_images)
balanced_labels.extend([3] * len(selected_happy_images))


def augment_image(image):
    """Applies random augmentations to an image using OpenCV."""
    
    if random.random() > 0.5:
        image = cv2.flip(image, 1)
    
    angle = random.uniform(-10, 10)
    M = cv2.getRotationMatrix2D((image.shape[1] / 2, image.shape[0] / 2), angle, 1)
    image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))

    tx = random.uniform(-0.1, 0.1) * image.shape[1]
    ty = random.uniform(-0.1, 0.1) * image.shape[0]
    M = np.float32([[1, 0, tx], [0, 1, ty]])
    image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))

    scale = random.uniform(0.8, 1.2)
    image = cv2.resize(image, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)

    brightness = random.uniform(0.8, 1.2)
    contrast = random.uniform(0.8, 1.2)
    image = np.clip(brightness * image + contrast, 0, 1)

    return image


categories_to_augment = {
    1: 5000,  
    6: 5000,  
    2: 5000,  
    0: 5000   
}

for category, target_count in categories_to_augment.items():
    category_images = [img for img, label in zip(train_images, train_labels) if label == category]
    balanced_images.extend(category_images)
    balanced_labels.extend([category] * len(category_images))
    
    # Augment to reach the target count
    num_augmentations_needed = target_count - len(category_images)
    for _ in range(num_augmentations_needed):
        image = random.choice(category_images)
        augmented_image = augment_image(image)
        balanced_images.append(augmented_image)
        balanced_labels.append(category)


unaltered_categories = [5, 4] 
for category in unaltered_categories:
    category_images = [img for img, label in zip(train_images, train_labels) if label == category]
    balanced_images.extend(category_images)
    balanced_labels.extend([category] * len(category_images))


for label in set(balanced_labels):
    label_dir = os.path.join(balanced_dir, str(label))
    os.makedirs(label_dir, exist_ok=True)
    
for i, (img, label) in enumerate(zip(balanced_images, balanced_labels)):
    img_path = os.path.join(balanced_dir, str(label), f"{label}_{i}.png")
    cv2.imwrite(img_path, (img * 255).astype('uint8'))

print("Dataset balancing complete. Saved to:", balanced_dir)

# ====== FEATURE EXTRACTION ON BALANCED DATASET ======

def apply_lbp(image, radius, n_points):
    lbp = local_binary_pattern(image, n_points, radius, method="uniform")
    return lbp

# LBP Parameters
radius = 3
n_points = 24
X_lbp_features = []
y_labels = []


for label in os.listdir(balanced_dir):
    label_dir = os.path.join(balanced_dir, label)
    for img_file in os.listdir(label_dir):
        img_path = os.path.join(label_dir, img_file)
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  

        
        img_resized = cv2.resize(img, (48, 48))

        
        lbp_features = apply_lbp(img_resized, radius, n_points)
        lbp_flatten = lbp_features.flatten()

        X_lbp_features.append(lbp_flatten)
        y_labels.append(int(label))


X_lbp_features = np.array(X_lbp_features)
y_labels = np.array(y_labels)
np.save('X_lbp_features.npy', X_lbp_features)
np.save('y_labels.npy', y_labels)


data = pd.DataFrame(X_lbp_features)
data['label'] = y_labels
data.to_csv('lbp_features.csv', index=False)

print("LBP feature extraction complete and saved.")
